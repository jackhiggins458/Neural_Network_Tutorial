{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19be7f51-9e45-4130-9f76-0ac32176d54a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# üöÄ Session 5 - Where to from here? \n",
    "And thats a wrap! Thanks for attending, we hope you learned a bunch about neural networks and had some fun. If you're interested in learning more, check out the resources, recommendations and challenges below. We'll be around, and we're happy to chat about any of this content, or anything else covered in the previous sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61e7b6-b7f5-4f62-8026-a301b96ab973",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üßëüèª‚Äçüíª Want to learn more about coding in R? \n",
    "- Learn more about [Jupyter Notebooks](https://jupyterlab.readthedocs.io/en/stable/user/notebook.html) and the [Jupyter Lab interface](https://jupyterlab.readthedocs.io/en/stable/user/interface.html) from the official documentation.\n",
    "- [Hands-On Programming with R, Garrett Grolemund](https://rstudio-education.github.io/hopr/) - A brief, project based introduction to R\n",
    "- [Introduction to Programming with R](https://discdown.org/rprogramming/) - A slightly longer, more thorough, but still beginner friendly introduction to R\n",
    "- [R-Studio Education](https://education.rstudio.com/learn/beginner/) - Lots of cool resources here!\n",
    "- [Stack overflow](https://stackoverflow.com/questions/tagged/r) - For finding solutions to common problems.\n",
    "- Ask your colleagues!\n",
    "\n",
    "## ü§ñ Want to learn more about neural networks and/or machine learning more broadly? \n",
    "- **Join our next session on Neural Networks on Tuesday December 7th!**\n",
    "- Join the ABS Machine Learning Community of Practice \n",
    "- [3Blue1Brown Neural networks series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - Highly recommended, fantastic visual and intuitive introduction.\n",
    "- [StatsQuest youtube channel](https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1) - Another entertaining and super instructive introduction to neural networks!\n",
    "- [Kaggle](https://www.kaggle.com/) - Learn from others and find lots of free data sets to play with!\n",
    "- [Neural Networks and Deep Learning, Michael Nielsen](http://neuralnetworksanddeeplearning.com/) - A thorough, beginner friendly written introduction.\n",
    "- [MNIST neural network visualised](https://www.cs.ryerson.ca/~aharley/vis/fc/)\n",
    "\n",
    "## ‚ö†Ô∏è More advanced topics that we would have covered if we had more time\n",
    "- Tuning hyper-parameters\n",
    "- Loss functions\n",
    "- Creating networks with multiple layers\n",
    "- Efficient/practical training of networks using stochastic gradient descent\n",
    "- Comparing NNs against other statistical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d8b933-4ea0-4be3-8ee6-df28634014fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## üî• Session 4 Extra challenges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488e841-5b19-4e5c-9678-a75a25e5fec5",
   "metadata": {},
   "source": [
    "If you're keen to dive a little bit deeper into some of the Session 4 content, here are some more challenging tasks to try."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366157f2-a84c-41db-ab38-2f59724e35a8",
   "metadata": {},
   "source": [
    "###  üå∂Ô∏è üôÇ Mild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea3005-59d7-47d2-acff-27416bf3b44e",
   "metadata": {},
   "source": [
    "Suitable for beginners, no additional experience expected.\n",
    "\n",
    "- **Setting the learning rate:** We didn't talk much about the learning rate. Try training the network with a few different values. What happens?\n",
    "\n",
    "- **Increasing the accuracy of the model:** \n",
    "The current ~80% accuracy is not bad, but leaves room for improvement. Play around with the parameters of the model and the training processs to see if you can get a better accuracy.\n",
    "\n",
    "- **Leaving in the labels:** When we created our testing data, we stripped out the data labels. What would happen if we kept the labels, and removed some other row instead? Try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f32865-ca2c-4ea3-bfce-c6868e06ebeb",
   "metadata": {},
   "source": [
    "###  üå∂Ô∏èüå∂Ô∏è üò≥ Spicy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce958305-b87f-484c-a1f3-e7f95a74bf1f",
   "metadata": {},
   "source": [
    "Coding and/or some math experience will be helpful, you might need to write some code yourself. \n",
    "\n",
    "- **Understanding the math of forward prop:** Take a look back at the forward propagation function, and try to develop an understanding of exactly what's going on.\n",
    "\n",
    "- **Passing in random noise:** Create a matrix full of random values and feed it through a trained network. What happens? Does this make sense?\n",
    "\n",
    "- **Visualising weights:** Sometimes it is hard to understand what's going on inside a neural network. In these cases, data visualisations can be a great aid! Think about how you could visualise the weights that connect all neurons in the input layer to the first neuron in the hidden layer. Try creating the visualisation in R if you're keen!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966a419-fb1c-4dbd-a7f4-d0e37bc33878",
   "metadata": {},
   "source": [
    "### üå∂Ô∏èüå∂Ô∏èüå∂Ô∏è ü•µ Flaming "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e87d0-67a0-4eeb-9100-e74ef0843acd",
   "metadata": {},
   "source": [
    "Coding + math experience, patience and high level of enthusiasm recommend, these aren't easy! \n",
    "\n",
    "- **Understanding the math of backprop:** Take a look back at the back propagation function, and try to develop an understanding of exactly what's going on.\n",
    "\n",
    "- **Trying other statistical models:** Although we've looked at using neural networks to classify digits, this problem is relatively simple, and other statistical methods can get high accuracies too. Try another model (e.g a linear regression or a random forest) and see how the performance compares. \n",
    "\n",
    "- **More hidden layers:** In our example, we only included one hidden layer in the network. Extend the model so that an arbitrary number of hidden layers can be used.\n",
    "\n",
    "- **Using a NN package:** Have a look at the [neuralnet](https://cran.r-project.org/web/packages/neuralnet/index.html) package, and try using the functions it provides to create and train a neural network on the MNIST data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
